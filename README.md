This Script runs a local server of "CYFRAGOVPL/Llama-PLLuM-8B-instruct". I highly recommend to change "cache_dir" into your desired location

Prerequisites:
Python 3.11.7 or later,
pip install transformers accelerate torch,
Depends on preferences but for me it's Visual Studio Code

Sources:
https://huggingface.co/CYFRAGOVPL/Llama-PLLuM-8B-instruct,
https://docs.python.org/3/library/venv.html
